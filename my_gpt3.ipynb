{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled67.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JPATuJNXNibP"
      ],
      "authorship_tag": "ABX9TyPcA+26a4nhLSwHrwQlTntk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be29a99955404e62b1ecdb606ec0c2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53dcdfaa97304c3b8ff3632799c93815",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f12f025acaf44b0989e657502a775e2b",
              "IPY_MODEL_3c5f74c3abf1404fbcfda9b5d3e396f5",
              "IPY_MODEL_33150860cfde4ed1adac914e275e976c"
            ]
          }
        },
        "53dcdfaa97304c3b8ff3632799c93815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f12f025acaf44b0989e657502a775e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f94cbe1718c64c0599d77470de3e7fb5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_acc804867632469e87fb5446e1b6a926"
          }
        },
        "3c5f74c3abf1404fbcfda9b5d3e396f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b6e2ef76610d4fc7af6ce2fd9148e74e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1713123,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1713123,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_574a7d31d8f84469be6acfbdfcfbd31a"
          }
        },
        "33150860cfde4ed1adac914e275e976c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32ee5a0d9da04ef6a3d86e07939b02e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.63M/1.63M [00:00&lt;00:00, 2.82MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_649d2e57f752411ebc328c90d831099e"
          }
        },
        "f94cbe1718c64c0599d77470de3e7fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "acc804867632469e87fb5446e1b6a926": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6e2ef76610d4fc7af6ce2fd9148e74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "574a7d31d8f84469be6acfbdfcfbd31a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32ee5a0d9da04ef6a3d86e07939b02e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "649d2e57f752411ebc328c90d831099e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "004400a62f1a42bea250b06ce9ea4ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c8090ed24db1486b910628fb21bc4cd0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e8386231de50416eb02306b0f6f8e7e4",
              "IPY_MODEL_dfd936fc9be7483f9ae09f9eef9b440e",
              "IPY_MODEL_a23f50842cf14c67879b0ae1172b69e2"
            ]
          }
        },
        "c8090ed24db1486b910628fb21bc4cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8386231de50416eb02306b0f6f8e7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a9b1731c1ff4187ab99cd6960748514",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56c1470694634fcc8279cfd79e599c0d"
          }
        },
        "dfd936fc9be7483f9ae09f9eef9b440e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3233b0cddae64d618247e8e31e45ba83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1270925,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1270925,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e39e84f5bf5420f83422f79a4c93a89"
          }
        },
        "a23f50842cf14c67879b0ae1172b69e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_12f476c5bc914d3baab63154c681118f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.21M/1.21M [00:00&lt;00:00, 1.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbf3f116efbd4a29b156859d3a5a7a53"
          }
        },
        "7a9b1731c1ff4187ab99cd6960748514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56c1470694634fcc8279cfd79e599c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3233b0cddae64d618247e8e31e45ba83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e39e84f5bf5420f83422f79a4c93a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12f476c5bc914d3baab63154c681118f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbf3f116efbd4a29b156859d3a5a7a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c555824b60e04b239ec36001aec33064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5805dc2afaf24cf68f0c3fa8b1739fa6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_40cd753fbac7426fa0405553ab28dd17",
              "IPY_MODEL_f139c8d0ae4844889c5f4baa379e1a3e",
              "IPY_MODEL_23ca7bc0ec874a9fa7199e1cccb21a6d"
            ]
          }
        },
        "5805dc2afaf24cf68f0c3fa8b1739fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40cd753fbac7426fa0405553ab28dd17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_614dff6028954b3d92590d6a2a62db9d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ff0c080d0be47d8988b493daeadf375"
          }
        },
        "f139c8d0ae4844889c5f4baa379e1a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b6e10a280ee445eb84b2b9cef1e4fee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 608,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 608,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8dd197485cc34cde839e5fac3e696069"
          }
        },
        "23ca7bc0ec874a9fa7199e1cccb21a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2358ba3b0d4c4e20b3795d528b2a367d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 608/608 [00:00&lt;00:00, 6.50kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93e3c83a8b8848e2969f44d32abb9554"
          }
        },
        "614dff6028954b3d92590d6a2a62db9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ff0c080d0be47d8988b493daeadf375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b6e10a280ee445eb84b2b9cef1e4fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8dd197485cc34cde839e5fac3e696069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2358ba3b0d4c4e20b3795d528b2a367d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93e3c83a8b8848e2969f44d32abb9554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1fd65b0014a429b8ff3e69a8496ef2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8fae9da8b4c14f3088ecce69066586e4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f1f1d27fd954402f8f87e6d85784b069",
              "IPY_MODEL_dfd05f7b64f9439893090066abf1a648",
              "IPY_MODEL_eb85a2914bb84e9a8997f3236ee30dec"
            ]
          }
        },
        "8fae9da8b4c14f3088ecce69066586e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1f1d27fd954402f8f87e6d85784b069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b0f7a6bf0c3142569d0fbf571718af0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d14b06418914b26aca9a5e22f5c3f44"
          }
        },
        "dfd05f7b64f9439893090066abf1a648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2f11a39f3a64c6cae75cfc8b0cab032",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 551290714,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 551290714,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7874ee7e9ed470699ee23acda8ef812"
          }
        },
        "eb85a2914bb84e9a8997f3236ee30dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ce90de3d8ec492bb98dec4d1ee471a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 526M/526M [00:13&lt;00:00, 40.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_442e11a65ecd41509ac54707def94951"
          }
        },
        "b0f7a6bf0c3142569d0fbf571718af0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d14b06418914b26aca9a5e22f5c3f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2f11a39f3a64c6cae75cfc8b0cab032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7874ee7e9ed470699ee23acda8ef812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ce90de3d8ec492bb98dec4d1ee471a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "442e11a65ecd41509ac54707def94951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/congrats_generator/blob/feature%233/my_gpt3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/github/sberbank-ai/ru-gpts/blob/master/examples/Finetune_RuGPTs_with_HF.ipynb#scrollTo=aZ-4Kav28cH0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MeNPO4kQhEh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORT**"
      ],
      "metadata": {
        "id": "JPATuJNXNibP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "nCxbSiVTNlN8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVqsMoIU6J0X",
        "outputId": "9801f123-4cee-43f7-a7a2-3e8b080e3969"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 437 kB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 27.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoNm9cNk9kIY",
        "outputId": "2d613a12-6705-4703-f2b0-6cd8c866c5a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 6.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm boto3 requests regex sacremoses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcU-kExe99IX",
        "outputId": "44666792-fe93-438b-c7ce-12b5ca12a8e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.20.25-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (0.0.46)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting botocore<1.24.0,>=1.23.25\n",
            "  Downloading botocore-1.23.25-py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.25->boto3) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.25->boto3) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.20.25 botocore-1.23.25 jmespath-0.10.0 s3transfer-0.5.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig"
      ],
      "metadata": {
        "id": "1ri4axMy9p7S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J5q0xqDA6Bug"
      },
      "outputs": [],
      "source": [
        "# model = torch.hub.load('huggingface/transformers', 'modelForCausalLM', 'gpt2')   \n",
        "#  # Download model and configuration from huggingface.co and cache.\n",
        "# # model = torch.hub.load('huggingface/transformers', 'modelForCausalLM', './test/saved_model/')  \n",
        "# # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n",
        "# model = torch.hub.load('huggingface/transformers', 'modelForCausalLM', 'gpt2', output_attentions=True)  \n",
        "# # Update configuration during loading\n",
        "# assert model.config.output_attentions == True\n",
        "# # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n",
        "# config = AutoConfig.from_pretrained('bert-base-uncased')\n",
        "# # AutoConfig.from_pretrained('bert-base-uncased')\n",
        "# # model = torch.hub.load('huggingface/transformers', 'modelForCausalLM', \n",
        "# #                        './tf_model/gpt_tf_checkpoint.ckpt.index', from_tf=True, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyvHuVMUJMN8",
        "outputId": "6ec09b13-9b54-4780-ba59-c2edffb873a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 93155, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 93155 (delta 9), reused 44 (delta 7), pack-reused 93095\u001b[K\n",
            "Receiving objects: 100% (93155/93155), 77.76 MiB | 13.04 MiB/s, done.\n",
            "Resolving deltas: 100% (67382/67382), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n",
        "# !pip install wandb; wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f550SIVJaTo",
        "outputId": "c1c06549-54ed-4f69-d661-d9213df0575b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.42.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xEJhcTFMJ8m-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "D7pZJGte7t5j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install awscli\n",
        "!aws s3 sync --no-sign-request s3://models.dobro.ai/gpt2/ru/unfreeze_all gpt2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2YagUWAHCznl",
        "outputId": "bb757994-48a9-4381-ea58-38609fe9238e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting awscli\n",
            "  Downloading awscli-1.22.25-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 8.6 MB/s \n",
            "\u001b[?25hCollecting rsa<4.8,>=3.1.2\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting docutils<0.16,>=0.10\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "\u001b[K     |████████████████████████████████| 547 kB 60.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from awscli) (0.5.0)\n",
            "Collecting PyYAML<5.5,>=3.10\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 68.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: botocore==1.23.25 in /usr/local/lib/python3.7/dist-packages (from awscli) (1.23.25)\n",
            "Collecting colorama<0.4.4,>=0.2.5\n",
            "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.23.25->awscli) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore==1.23.25->awscli) (1.25.11)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.23.25->awscli) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.23.25->awscli) (1.15.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.4.8)\n",
            "Installing collected packages: rsa, PyYAML, docutils, colorama, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.8\n",
            "    Uninstalling rsa-4.8:\n",
            "      Successfully uninstalled rsa-4.8\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-5.4.1 awscli-1.22.25 colorama-0.4.3 docutils-0.15.2 rsa-4.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "rsa",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 674 Bytes/2.3 GiB (1.3 KiB/s) with 10 file(s) remaining\rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/m_checkpoint-3364613/config.json to gpt2/m_checkpoint-3364613/config.json\n",
            "Completed 674 Bytes/2.3 GiB (1.3 KiB/s) with 9 file(s) remaining\rCompleted 681 Bytes/2.3 GiB (1.2 KiB/s) with 9 file(s) remaining\rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/m_checkpoint-3364613/step.txt to gpt2/m_checkpoint-3364613/step.txt\n",
            "Completed 681 Bytes/2.3 GiB (1.2 KiB/s) with 8 file(s) remaining\rCompleted 688 Bytes/2.3 GiB (1.2 KiB/s) with 8 file(s) remaining\rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/s_checkpoint-1900000/step.txt to gpt2/s_checkpoint-1900000/step.txt\n",
            "Completed 688 Bytes/2.3 GiB (1.2 KiB/s) with 7 file(s) remaining\rCompleted 2.0 KiB/2.3 GiB (3.6 KiB/s) with 7 file(s) remaining  \rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/m_checkpoint-3364613/training_args.bin to gpt2/m_checkpoint-3364613/training_args.bin\n",
            "Completed 2.0 KiB/2.3 GiB (3.6 KiB/s) with 6 file(s) remaining\rCompleted 3.4 KiB/2.3 GiB (5.9 KiB/s) with 6 file(s) remaining\rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/s_checkpoint-1900000/training_args.bin to gpt2/s_checkpoint-1900000/training_args.bin\n",
            "download: s3://models.dobro.ai/gpt2/ru/unfreeze_all/s_checkpoint-1900000/config.json to gpt2/s_checkpoint-1900000/config.json\n",
            "download: s3://models.dobro.ai/gpt2/ru/unfreeze_all/s_checkpoint-1900000/encoder.model to gpt2/s_checkpoint-1900000/encoder.model\n",
            "download: s3://models.dobro.ai/gpt2/ru/unfreeze_all/m_checkpoint-3364613/encoder.model to gpt2/m_checkpoint-3364613/encoder.model\n",
            "download: s3://models.dobro.ai/gpt2/ru/unfreeze_all/s_checkpoint-1900000/pytorch_model.bin to gpt2/s_checkpoint-1900000/pytorch_model.bin\n",
            "download: s3://models.dobro.ai/gpt2/ru/unfreeze_all/m_checkpoint-3364613/pytorch_model.bin to gpt2/m_checkpoint-3364613/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MMw690sPZHAo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREPARE DATA**"
      ],
      "metadata": {
        "id": "ICdrPvdDNbEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/DmitryKutsev/congrats_generator/feature%233/crawler/curr_congrats.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbc_qWXLNgjt",
        "outputId": "dc2a0571-702b-45d8-e75e-fd488bf1d39e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-21 18:59:03--  https://raw.githubusercontent.com/DmitryKutsev/congrats_generator/feature%233/crawler/curr_congrats.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1471875 (1.4M) [text/plain]\n",
            "Saving to: ‘curr_congrats.txt’\n",
            "\n",
            "curr_congrats.txt   100%[===================>]   1.40M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-12-21 18:59:04 (34.1 MB/s) - ‘curr_congrats.txt’ saved [1471875/1471875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('curr_congrats.txt') as handler:\n",
        "  full_text = handler.read()\n",
        "full_text[:3000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "tjTgJgTvN0mH",
        "outputId": "c92fd635-cbb2-4651-c5a0-aae494b4f2bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nTITLE\\nЭдварду Радзинскому, писателю, драматургу, сценаристу\\nCONTENT\\n Уважаемый Эдвард Станиславович!Примите поздравления с\\xa085-летием.Человек многогранного дарования и\\xa0большой созидательной энергии, Вы по\\xa0праву входите в\\xa0число признанных\\nдраматургов, мастеров современного театрального искусства. И\\xa0конечно, Вас\\nхорошо знают и\\xa0любят как автора целого ряда просветительских проектов, чьё\\nтворчество завоевало сердца самой широкой аудитории, в\\xa0том числе молодёжи.Желаю доброго здоровья, благополучия и\\xa0бодрости\\nдуха. Владимир Путин     Статус материала Опубликован в\\xa0разделе: Телеграммы  Ссылка на материал: kremlin.ru/d/66751   Текстовая версия      \\nEND\\n\\nTITLE\\nКоллективу радиостанции «Орфей»\\nCONTENT\\n Дорогие друзья!Поздравляю вас со\\xa0знаменательным юбилеем\\xa0– 30-летием радиостанции «Орфей».Все эти годы ваш коллектив объединяет настоящих единомышленников, профессионалов, преданных высокому искусству, стремящихся внести свой вклад в\\xa0сбережение лучших традиций отечественной культуры. Вы сформировали обширный фонд просветительских, познавательных программ, завоевали признание людей самого разного возраста, слушателей в\\xa0России и\\xa0за\\xa0рубежом.Особо отмечу ваши уникальные медиапроекты, которые открывают широкий доступ к\\xa0онлайн-трансляциям концертов и\\xa0спектаклей, способствуют изучению и\\xa0сохранению творческого наследия выдающихся русских композиторов, воссозданию ранее утерянных музыкальных произведений и\\xa0нотных записей. Такая многогранная созидательная работа достойна глубокого уважения.Желаю новых успехов, благополучия и\\xa0всего наилучшего. Владимир Путин     Статус материала Опубликован в\\xa0разделе: Телеграммы  Ссылка на материал: kremlin.ru/d/66743   Текстовая версия      \\nEND\\n\\nTITLE\\nМихаилу Ковальчуку, президенту НИЦ «Курчатовский институт»\\nCONTENT\\n Уважаемый Михаил Валентинович!Примите мои поздравления по\\xa0случаю 75-летнего юбилея.Вы по\\xa0праву входите в\\xa0число исследователей, чьи фундаментальные труды и\\xa0практические наработки способствовали созданию в\\xa0России перспективных направлений науки и\\xa0прорывных технологий, заложили основу для их эффективного развития на\\xa0годы вперёд. И\\xa0конечно, Вас ценят как талантливого педагога и\\xa0организатора, человека, наделённого большой творческой энергией, который вносит значимый личный вклад в\\xa0решение задач, стоящих перед знаменитым Курчатовским институтом, много сил и\\xa0времени уделяет просветительской, общественной деятельности.Желаю Вам здоровья, успехов и\\xa0реализации намеченных планов. Владимир Путин     Статус материала Опубликован в\\xa0разделе: Телеграммы  Ссылка на материал: kremlin.ru/d/66739   Текстовая версия      \\nEND\\n\\nTITLE\\nИрине Андреевой и\\xa0Ивану Штылю, победителям чемпионата мира по\\xa0гребле на\\xa0байдарках и\\xa0каноэ 2021\\xa0года в\\xa0Копенгагене в\\xa0каноэ-двойке в\\xa0миксте на\\xa0дистанции 200 метров\\nCONTENT\\n Уважаемые Ирина Александровна и\\xa0Иван Александрович!Поздравляю вас с\\xa0успешным выступлением на\\xa0чемпионате мира в\\xa0Копенгагене.Благодаря таланту, волевому характеру и\\xa0настрою на\\xa0победу вы обошли сильных и\\xa0именитых соперников, продемонстрировали наст'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_text.split('END')[:3][0].replace('\\n', '').split('CONTENT')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU9TBsuAOSrZ",
        "outputId": "04fc8c1d-0300-4674-8bcb-ae666b63d4e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TITLEЭдварду Радзинскому, писателю, драматургу, сценаристу',\n",
              " ' Уважаемый Эдвард Станиславович!Примите поздравления с\\xa085-летием.Человек многогранного дарования и\\xa0большой созидательной энергии, Вы по\\xa0праву входите в\\xa0число признанныхдраматургов, мастеров современного театрального искусства. И\\xa0конечно, Васхорошо знают и\\xa0любят как автора целого ряда просветительских проектов, чьётворчество завоевало сердца самой широкой аудитории, в\\xa0том числе молодёжи.Желаю доброго здоровья, благополучия и\\xa0бодростидуха. Владимир Путин     Статус материала Опубликован в\\xa0разделе: Телеграммы  Ссылка на материал: kremlin.ru/d/66751   Текстовая версия      ']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles_list = []\n",
        "congrats_list = []\n",
        "\n",
        "for letter in full_text.split('END'):\n",
        "  letter = letter.replace('\\n', '').replace('TITLE', '')\n",
        "  # print(letter)\n",
        "  # print(letter.split('CONTENT'))\n",
        "  # print(letter.split('CONTENT'))\n",
        "  # break\n",
        "  if len(letter.split('CONTENT')) > 1:\n",
        "    titles_list.append(letter.split('CONTENT')[0])\n",
        "    congrats_list.append(letter.split('CONTENT')[1])\n",
        "\n",
        "print(titles_list[:3])\n",
        "print(congrats_list[:3])\n",
        "print(len(titles_list))\n",
        "print(len(congrats_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfgJgy0hOU3S",
        "outputId": "2c0c69f7-d512-4325-ab83-fa0e8b3121de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Эдварду Радзинскому, писателю, драматургу, сценаристу', 'Коллективу радиостанции «Орфей»', 'Михаилу Ковальчуку, президенту НИЦ «Курчатовский институт»']\n",
            "[' Уважаемый Эдвард Станиславович!Примите поздравления с\\xa085-летием.Человек многогранного дарования и\\xa0большой созидательной энергии, Вы по\\xa0праву входите в\\xa0число признанныхдраматургов, мастеров современного театрального искусства. И\\xa0конечно, Васхорошо знают и\\xa0любят как автора целого ряда просветительских проектов, чьётворчество завоевало сердца самой широкой аудитории, в\\xa0том числе молодёжи.Желаю доброго здоровья, благополучия и\\xa0бодростидуха. Владимир Путин     Статус материала Опубликован в\\xa0разделе: Телеграммы  Ссылка на материал: kremlin.ru/d/66751   Текстовая версия      ', ' Дорогие друзья!Поздравляю вас со\\xa0знаменательным юбилеем\\xa0– 30-летием радиостанции «Орфей».Все эти годы ваш коллектив объединяет настоящих единомышленников, профессионалов, преданных высокому искусству, стремящихся внести свой вклад в\\xa0сбережение лучших традиций отечественной культуры. Вы сформировали обширный фонд просветительских, познавательных программ, завоевали признание людей самого разного возраста, слушателей в\\xa0России и\\xa0за\\xa0рубежом.Особо отмечу ваши уникальные медиапроекты, которые открывают широкий доступ к\\xa0онлайн-трансляциям концертов и\\xa0спектаклей, способствуют изучению и\\xa0сохранению творческого наследия выдающихся русских композиторов, воссозданию ранее утерянных музыкальных произведений и\\xa0нотных записей. Такая многогранная созидательная работа достойна глубокого уважения.Желаю новых успехов, благополучия и\\xa0всего наилучшего. Владимир Путин     Статус материала Опубликован в\\xa0разделе: Телеграммы  Ссылка на материал: kremlin.ru/d/66743   Текстовая версия      ', ' Уважаемый Михаил Валентинович!Примите мои поздравления по\\xa0случаю 75-летнего юбилея.Вы по\\xa0праву входите в\\xa0число исследователей, чьи фундаментальные труды и\\xa0практические наработки способствовали созданию в\\xa0России перспективных направлений науки и\\xa0прорывных технологий, заложили основу для их эффективного развития на\\xa0годы вперёд. И\\xa0конечно, Вас ценят как талантливого педагога и\\xa0организатора, человека, наделённого большой творческой энергией, который вносит значимый личный вклад в\\xa0решение задач, стоящих перед знаменитым Курчатовским институтом, много сил и\\xa0времени уделяет просветительской, общественной деятельности.Желаю Вам здоровья, успехов и\\xa0реализации намеченных планов. Владимир Путин     Статус материала Опубликован в\\xa0разделе: Телеграммы  Ссылка на материал: kremlin.ru/d/66739   Текстовая версия      ']\n",
            "888\n",
            "888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Title': titles_list,\n",
        "        'Content': congrats_list}\n",
        "\n",
        "my_df = pd.DataFrame(data)\n",
        "my_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "D4S_hWq2QK7k",
        "outputId": "71e16fd6-b2e3-4518-aa06-bf524e7aa2f3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Эдварду Радзинскому, писателю, драматургу, сце...</td>\n",
              "      <td>Уважаемый Эдвард Станиславович!Примите поздра...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Коллективу радиостанции «Орфей»</td>\n",
              "      <td>Дорогие друзья!Поздравляю вас со знаменательн...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Михаилу Ковальчуку, президенту НИЦ «Курчатовск...</td>\n",
              "      <td>Уважаемый Михаил Валентинович!Примите мои поз...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ирине Андреевой и Ивану Штылю, победителям чем...</td>\n",
              "      <td>Уважаемые Ирина Александровна и Иван Александ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Работникам и ветеранам оборонно-промышленного ...</td>\n",
              "      <td>Уважаемые друзья!Поздравляю вас с Днём оружей...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>Жителям Республики Мордовия</td>\n",
              "      <td>Дорогие друзья!Поздравляю вас с юбилеем – 75-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>Коллективу Института физических проблем им.П.Л...</td>\n",
              "      <td>Поздравляю коллектив института с 70-летием со...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>Жителям Красноярского края</td>\n",
              "      <td>Уважаемые друзья!Поздравляю вас с 70-летием с...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>В.А.ЛОГИНОВУ</td>\n",
              "      <td>Уважаемый Владимир Александрович!Поздравляю В...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>Патриарху Московскому и всея Руси Алексию II</td>\n",
              "      <td>Ваше Святейшество!От всего сердца поздравляю ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>888 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Title                                            Content\n",
              "0    Эдварду Радзинскому, писателю, драматургу, сце...   Уважаемый Эдвард Станиславович!Примите поздра...\n",
              "1                      Коллективу радиостанции «Орфей»   Дорогие друзья!Поздравляю вас со знаменательн...\n",
              "2    Михаилу Ковальчуку, президенту НИЦ «Курчатовск...   Уважаемый Михаил Валентинович!Примите мои поз...\n",
              "3    Ирине Андреевой и Ивану Штылю, победителям чем...   Уважаемые Ирина Александровна и Иван Александ...\n",
              "4    Работникам и ветеранам оборонно-промышленного ...   Уважаемые друзья!Поздравляю вас с Днём оружей...\n",
              "..                                                 ...                                                ...\n",
              "883                        Жителям Республики Мордовия   Дорогие друзья!Поздравляю вас с юбилеем – 75-...\n",
              "884  Коллективу Института физических проблем им.П.Л...   Поздравляю коллектив института с 70-летием со...\n",
              "885                         Жителям Красноярского края   Уважаемые друзья!Поздравляю вас с 70-летием с...\n",
              "886                                       В.А.ЛОГИНОВУ   Уважаемый Владимир Александрович!Поздравляю В...\n",
              "887       Патриарху Московскому и всея Руси Алексию II   Ваше Святейшество!От всего сердца поздравляю ...\n",
              "\n",
              "[888 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPNGyp4Gq8gX",
        "outputId": "cbed0c97-a7ec-4ca0-fcd8-465cb8b077ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 18.4 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 102 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 122 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 163 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 174 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 184 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 194 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 204 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 215 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 225 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 235 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 245 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 256 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 266 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 276 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 286 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 296 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 306 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.14.1)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 60.3 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.2.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 22.4 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 44.0 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.17.0 frozenlist-1.2.0 fsspec-2021.11.1 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone  https://github.com/sberbank-ai/ru-gpts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chdG-tIs8EKM",
        "outputId": "23d42af7-3f24-47b8-ae64-5b0c6fa859c6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ru-gpts'...\n",
            "remote: Enumerating objects: 683, done.\u001b[K\n",
            "remote: Counting objects: 100% (178/178), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 683 (delta 110), reused 141 (delta 83), pack-reused 505\u001b[K\n",
            "Receiving objects: 100% (683/683), 413.81 KiB | 2.13 MiB/s, done.\n",
            "Resolving deltas: 100% (410/410), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "# datasets = load_dataset(\"text\", data_files={\"train\": path_to_train.txt, \"validation\": path_to_validation.txt}"
      ],
      "metadata": {
        "id": "kj1K38Ihq2KM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df['Sum'] = [my_df['Title'].tolist()[i] + my_df['Content'].tolist()[i] for i in range(len(my_df))]\n",
        "my_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "cCSD2s7mNIFa",
        "outputId": "ed220d59-ab2f-41dc-f11c-ca51099547d3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Эдварду Радзинскому, писателю, драматургу, сце...</td>\n",
              "      <td>Уважаемый Эдвард Станиславович!Примите поздра...</td>\n",
              "      <td>Эдварду Радзинскому, писателю, драматургу, сце...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Коллективу радиостанции «Орфей»</td>\n",
              "      <td>Дорогие друзья!Поздравляю вас со знаменательн...</td>\n",
              "      <td>Коллективу радиостанции «Орфей» Дорогие друзья...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Михаилу Ковальчуку, президенту НИЦ «Курчатовск...</td>\n",
              "      <td>Уважаемый Михаил Валентинович!Примите мои поз...</td>\n",
              "      <td>Михаилу Ковальчуку, президенту НИЦ «Курчатовск...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ирине Андреевой и Ивану Штылю, победителям чем...</td>\n",
              "      <td>Уважаемые Ирина Александровна и Иван Александ...</td>\n",
              "      <td>Ирине Андреевой и Ивану Штылю, победителям чем...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Работникам и ветеранам оборонно-промышленного ...</td>\n",
              "      <td>Уважаемые друзья!Поздравляю вас с Днём оружей...</td>\n",
              "      <td>Работникам и ветеранам оборонно-промышленного ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>Жителям Республики Мордовия</td>\n",
              "      <td>Дорогие друзья!Поздравляю вас с юбилеем – 75-...</td>\n",
              "      <td>Жителям Республики Мордовия Дорогие друзья!Поз...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>Коллективу Института физических проблем им.П.Л...</td>\n",
              "      <td>Поздравляю коллектив института с 70-летием со...</td>\n",
              "      <td>Коллективу Института физических проблем им.П.Л...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>Жителям Красноярского края</td>\n",
              "      <td>Уважаемые друзья!Поздравляю вас с 70-летием с...</td>\n",
              "      <td>Жителям Красноярского края Уважаемые друзья!По...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>В.А.ЛОГИНОВУ</td>\n",
              "      <td>Уважаемый Владимир Александрович!Поздравляю В...</td>\n",
              "      <td>В.А.ЛОГИНОВУ Уважаемый Владимир Александрович!...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>Патриарху Московскому и всея Руси Алексию II</td>\n",
              "      <td>Ваше Святейшество!От всего сердца поздравляю ...</td>\n",
              "      <td>Патриарху Московскому и всея Руси Алексию II В...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>888 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Title  ...                                                Sum\n",
              "0    Эдварду Радзинскому, писателю, драматургу, сце...  ...  Эдварду Радзинскому, писателю, драматургу, сце...\n",
              "1                      Коллективу радиостанции «Орфей»  ...  Коллективу радиостанции «Орфей» Дорогие друзья...\n",
              "2    Михаилу Ковальчуку, президенту НИЦ «Курчатовск...  ...  Михаилу Ковальчуку, президенту НИЦ «Курчатовск...\n",
              "3    Ирине Андреевой и Ивану Штылю, победителям чем...  ...  Ирине Андреевой и Ивану Штылю, победителям чем...\n",
              "4    Работникам и ветеранам оборонно-промышленного ...  ...  Работникам и ветеранам оборонно-промышленного ...\n",
              "..                                                 ...  ...                                                ...\n",
              "883                        Жителям Республики Мордовия  ...  Жителям Республики Мордовия Дорогие друзья!Поз...\n",
              "884  Коллективу Института физических проблем им.П.Л...  ...  Коллективу Института физических проблем им.П.Л...\n",
              "885                         Жителям Красноярского края  ...  Жителям Красноярского края Уважаемые друзья!По...\n",
              "886                                       В.А.ЛОГИНОВУ  ...  В.А.ЛОГИНОВУ Уважаемый Владимир Александрович!...\n",
              "887       Патриарху Московскому и всея Руси Алексию II  ...  Патриарху Московскому и всея Руси Алексию II В...\n",
              "\n",
              "[888 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_ratio = 0.9\n",
        "df_train, df_test = train_test_split(my_df, train_size = train_test_ratio, random_state = 1)\n",
        "# train_valid_ratio = 7/9\n",
        "# df_train, df_valid = train_test_split(df_full_train, train_size = train_valid_ratio, random_state = 1)"
      ],
      "metadata": {
        "id": "COHxJSC5q2MV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(df, dest_path):\n",
        "    f = open(dest_path, 'w')\n",
        "    data = ''\n",
        "    summaries = df['Sum'].tolist()\n",
        "    # c = 0\n",
        "    # if c < 2:\n",
        "    #   print(summaries)\n",
        "    #   c += 1\n",
        "    for summary in summaries:\n",
        "        summary = str(summary).strip()\n",
        "        summary = re.sub(r\"\\s\", \" \", summary)\n",
        "        summary = re.sub(r\"\\n\", \"\", summary)\n",
        "        summary = re.sub(r\"Статус материала Опубликован в разделе: Телеграммы\", \"\", summary)\n",
        "        summary = re.sub(r\"Ссылка на материал:\", \"\", summary)\n",
        "        summary = re.sub(r\"Текстовая версия:\", \"\", summary)\n",
        "        summary = re.sub(r\"Ссылка на материал:\", \"\", summary)\n",
        "        summary = re.sub(r\"([a-zA-Z]+)\", \"\", summary)\n",
        "        summary = re.sub(r\"([0-9/*#@+]+)\", \"\", summary)\n",
        "        # bos_token = '<BOS>'\n",
        "        # eos_token = '<EOS>'\n",
        "        # data += bos_token + ' ' + summary + ' ' + eos_token + '\\n'\n",
        "        data += summary\n",
        "    # c = 0\n",
        "    # if c < 2:\n",
        "    #   print(data)\n",
        "    #   c += 1\n",
        "    f.write(data)"
      ],
      "metadata": {
        "id": "NsLD1R-jq2Ow"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!rm 'train.txt' 'test.txt'\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgP-mpMENZsn",
        "outputId": "8bd1bcec-eea9-4cd0-bbb4-f27cf2969149"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curr_congrats.txt  gpt2  ru-gpts  sample_data  transformers\n",
            "rm: cannot remove 'train.txt': No such file or directory\n",
            "rm: cannot remove 'test.txt': No such file or directory\n",
            "curr_congrats.txt  gpt2  ru-gpts  sample_data  transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "build_dataset(df_train, 'train.txt')\n",
        "build_dataset(df_test, 'test.txt')\n",
        "# build_dataset(df_valid, 'valid.txt')"
      ],
      "metadata": {
        "id": "ZVgfc00jqmkb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"anonymous-german-nlp/german-gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
        " \n",
        "train_path = 'train.txt'\n",
        "test_path = 'test.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "be29a99955404e62b1ecdb606ec0c2b4",
            "53dcdfaa97304c3b8ff3632799c93815",
            "f12f025acaf44b0989e657502a775e2b",
            "3c5f74c3abf1404fbcfda9b5d3e396f5",
            "33150860cfde4ed1adac914e275e976c",
            "f94cbe1718c64c0599d77470de3e7fb5",
            "acc804867632469e87fb5446e1b6a926",
            "b6e2ef76610d4fc7af6ce2fd9148e74e",
            "574a7d31d8f84469be6acfbdfcfbd31a",
            "32ee5a0d9da04ef6a3d86e07939b02e3",
            "649d2e57f752411ebc328c90d831099e",
            "004400a62f1a42bea250b06ce9ea4ada",
            "c8090ed24db1486b910628fb21bc4cd0",
            "e8386231de50416eb02306b0f6f8e7e4",
            "dfd936fc9be7483f9ae09f9eef9b440e",
            "a23f50842cf14c67879b0ae1172b69e2",
            "7a9b1731c1ff4187ab99cd6960748514",
            "56c1470694634fcc8279cfd79e599c0d",
            "3233b0cddae64d618247e8e31e45ba83",
            "7e39e84f5bf5420f83422f79a4c93a89",
            "12f476c5bc914d3baab63154c681118f",
            "cbf3f116efbd4a29b156859d3a5a7a53",
            "c555824b60e04b239ec36001aec33064",
            "5805dc2afaf24cf68f0c3fa8b1739fa6",
            "40cd753fbac7426fa0405553ab28dd17",
            "f139c8d0ae4844889c5f4baa379e1a3e",
            "23ca7bc0ec874a9fa7199e1cccb21a6d",
            "614dff6028954b3d92590d6a2a62db9d",
            "7ff0c080d0be47d8988b493daeadf375",
            "0b6e10a280ee445eb84b2b9cef1e4fee",
            "8dd197485cc34cde839e5fac3e696069",
            "2358ba3b0d4c4e20b3795d528b2a367d",
            "93e3c83a8b8848e2969f44d32abb9554"
          ]
        },
        "id": "Dt-01MWwg9q6",
        "outputId": "2f2dae41-5030-4429-a2c4-f6566d4813c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be29a99955404e62b1ecdb606ec0c2b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.63M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "004400a62f1a42bea250b06ce9ea4ada",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c555824b60e04b239ec36001aec33064",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm ./gpt-letters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQNJ3ZUeUlS1",
        "outputId": "478aea74-b4d8-458c-ef95-08f19f0a7e08"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove './gpt-letters': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.add_special_tokens({'bos_token': '<BOS>', 'eos_token': '<EOS>', 'mask_token': '<MASK>'})"
      ],
      "metadata": {
        "id": "ZrUClPmHVWGP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "\n",
        "def load_dataset(train_path,test_path,tokenizer):\n",
        "    train_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)\n",
        "     \n",
        "    test_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=test_path,\n",
        "          block_size=128)   \n",
        "    \n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return train_dataset, test_dataset, data_collator\n",
        "\n",
        "train_dataset, test_dataset, data_collator = load_dataset(train_path, test_path, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMuzZ8pbkcLE",
        "outputId": "fd8b4caa-5d43-4364-b5c6-fc88e7c312b9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TRAIN MODEL**"
      ],
      "metadata": {
        "id": "kX8ez-MZMTKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt-letters\", #The output directory\n",
        "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    # num_train_epochs=3, # number of training epochs\n",
        "    # per_device_train_batch_size=32, # batch size for training\n",
        "    # per_device_eval_batch_size=64,  # batch size for evaluation\n",
        "    num_train_epochs=3, # number of training epochs\n",
        "    per_device_train_batch_size=16, # batch size for training\n",
        "    per_device_eval_batch_size=24,  # batch size for evaluation\n",
        "    eval_steps = 400, # Number of update steps between two evaluations.\n",
        "    save_steps=150, # after # steps model is saved \n",
        "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
        "    prediction_loss_only=True,\n",
        "    )\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f1fd65b0014a429b8ff3e69a8496ef2f",
            "8fae9da8b4c14f3088ecce69066586e4",
            "f1f1d27fd954402f8f87e6d85784b069",
            "dfd05f7b64f9439893090066abf1a648",
            "eb85a2914bb84e9a8997f3236ee30dec",
            "b0f7a6bf0c3142569d0fbf571718af0a",
            "3d14b06418914b26aca9a5e22f5c3f44",
            "d2f11a39f3a64c6cae75cfc8b0cab032",
            "c7874ee7e9ed470699ee23acda8ef812",
            "4ce90de3d8ec492bb98dec4d1ee471a4",
            "442e11a65ecd41509ac54707def94951"
          ]
        },
        "id": "BJsgeivCkkKa",
        "outputId": "695518c9-3a2e-4409-e12f-bd37b1b5e5d7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1fd65b0014a429b8ff3e69a8496ef2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/526M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "LYVx4OsGk3DP",
        "outputId": "6df0a8b6-7dc4-4439-f355-34b7950a48a0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 989\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 186\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [186/186 1:24:55, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gpt-letters/checkpoint-150\n",
            "Configuration saved in ./gpt-letters/checkpoint-150/config.json\n",
            "Model weights saved in ./gpt-letters/checkpoint-150/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=186, training_loss=2.654388919953377, metrics={'train_runtime': 5124.6923, 'train_samples_per_second': 0.579, 'train_steps_per_second': 0.036, 'total_flos': 193813364736000.0, 'train_loss': 2.654388919953377, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_hdlyW_k61Z",
        "outputId": "d60c1edb-5944-455f-9cf7-aac04d1fe482"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gpt-letters\n",
            "Configuration saved in ./gpt-letters/config.json\n",
            "Model weights saved in ./gpt-letters/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# my_model = torch.load('./gpt-letters/pytorch_model.bin')\n",
        "from transformers import pipeline\n",
        "\n",
        "pu = pipeline('text-generation',model='./gpt-letters', tokenizer=tokenizer, max_length=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BQfswfh3XXc",
        "outputId": "8600c2be-b7a7-4cee-983c-2653e25ac2b3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file ./gpt-letters/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"./gpt-letters\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "loading configuration file ./gpt-letters/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"./gpt-letters\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.14.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "loading weights file ./gpt-letters/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./gpt-letters.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pu(\"Александру Сергеевичу Пушкину\")[0]['generated_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "U1npn-k-5olF",
        "outputId": "72b30f2b-7dd7-42f4-c31e-d5b443717a46"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Александру Сергеевичу Пушкину, народному артисту России Уважаемый Александр Сергеевич! Примите мои поздравления с -летием и самые добрые пожелания. Желаю Вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияАлександру Сергеевичу Пушкину, народному артисту России Уважаемый Александр Сергеевич! Примите мои поздравления с -летием и самые добрые пожелания. Желаю Вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияАлександру Сергеевичу Пушкину, народному артисту России Уважаемый Александр Сергеевич! Примите мои поздравления с -летием и самые добрые пожелания. Желаю Вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияАлександру Сергеевичу Пушкину, народному артисту России Уважаемый Александр Сергеевич! Примите мои поздравления с -летием и самые добрые пожелания. Желаю Вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияАлександру Сергеевичу Пушкину, народному артисту России Уважаемый Александр Сергеевич! Примите мои поздравления с -летием и самые добрые пожелания. Желаю Вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияАлександру Сергеевичу Пушкину, народному артисту России Уважаемый Александр Сергеевич! Примите мои поздравления с -летием и самые добрые пожелания. Владимир Путин       .   Текстовая версияАлександру Сергеевичу Пушкину, народному артисту России Уважаемый Александр Сергеевич! Примите мои поздравления с -летием и самые добрые пожелания. Желаю Вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияАлександру Сергеевичу Пушкину, народному артисту России Уважаемый Александр Сергеевич! Примите мои поздравления с -летием и самые добрые пожелания. Желаю Вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияАлександру Сергеевичу Пушкину, народному артисту России Уважаемый Александр Сергеевич! Примите мои поздравления с -летием и самые добрые пожелания. Желаю Вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияАлександру Сергеевичу Пушкину, народному артисту России Уважаемый Александр Сергеевич! Примите мои поздравления с -летием и самые добрые пожелания. Желаю Вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияАлександру Сергеевичу Пушкину, народному артисту России Уважаемый Александр Сергеевич! Примите мои'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pu(\"Кровавым убийцам детей\")[0]['generated_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "mUizYI4HlGHb",
        "outputId": "60f70968-5f84-413c-a0ca-dae138cebe97"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Кровавым убийцам детей и молодёжи Уважаемые друзья!Поздравляю вас с -летием создания Российского военно-исторического общества.В его стенах вы впервые познакомитесь с историей создания и развития Российского военно-исторического общества, с его богатейшим историческим, культурным, научным, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским, просветительским'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pu(\"Уважаемые осквернители святынь и насильники\")[0]['generated_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Lk-tHC1939g-",
        "outputId": "e50eb728-879d-41b3-d88c-f6116591ad44"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Уважаемые осквернители святынь и насильники!Поздравляю вас с праздником – Днём рождения Государственного Эрмитажа.Вы по праву принадлежите к числу выдающихся мастеров отечественной культуры, которые внесли большой вклад в развитие отечественной культуры, внесли значимый вклад в развитие отечественной культуры.Уверен, что и впредь вы будете достойно нести вахту служения искусству, бережно хранить богатейшие коллекции, бережно передавать их из поколения в поколение.Желаю вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияКоллективу и ветеранам Государственного Эрмитажа Дорогие друзья!Поздравляю вас с Днём рождения Государственного Эрмитажа.Вы по праву принадлежите к числу выдающихся мастеров отечественной культуры, внесли большой вклад в развитие отечественной культуры, внесли значимый вклад в развитие отечественной культуры.Уверен, что и впредь вы будете достойно нести вахту служения искусству, бережно хранить богатейшие коллекции, бережно передавать их из поколения в поколение.Желаю вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияКоллективу и ветеранам Государственного Эрмитажа Дорогие друзья!Поздравляю вас с Днём рождения Государственного Эрмитажа.Вы по праву принадлежите к числу выдающихся мастеров отечественной культуры, внесли большой вклад в развитие отечественной культуры, внесли значимый вклад в развитие отечественной культуры.Желаю вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияКоллективу и ветеранам Государственного Эрмитажа Дорогие друзья!Поздравляю вас с Днём рождения Государственного Эрмитажа.Вы по праву принадлежите к числу выдающихся мастеров отечественной культуры, внесли большой вклад в развитие отечественной культуры, внесли значимый вклад в развитие отечественной культуры.Уверен, что и впредь вы будете достойно нести вахту служения искусству, бережно хранить богатейшие коллекции, бережно передавать их из поколения в поколение.Владимир Путин       .   Текстовая версияКоллективу и ветеранам Государственного Эрмитажа Дорогие друзья!Поздравляю вас с Днём рождения Государственного Эрмитажа.Вы по праву принадлежите к числу выдающихся мастеров отечественной культуры, внесли большой вклад в развитие отечественной культуры, внесли значимый вклад в развитие отечественной культуры.Уверен, что и впредь вы будете достойно нести вахту служения искусству, бережно хранить богатейшие коллекции, бережно передавать их из поколения в поколение.Владимир Путин       .   Текстовая версияКоллективу и ветеранам Государственного Эрмитажа Дорогие друзья!Поздравляю вас с Днём рождения Государственного Эрмитажа.Вы по праву'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pu(\"Хочу сказать этому Обэме\")[0]['generated_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "KHJyOCWrpwuO",
        "outputId": "ba0f2e0b-24cc-46f6-87e5-e434bba2380c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Хочу сказать этому Обэме, что вы по праву принадлежите к числу тех, кто в течение многих лет бережно хранит и приумножает традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа.Желаю вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияКоллективу и ветеранам Государственного академического театра драмы имени А.С.Пушкина Дорогие друзья!Поздравляю вас с -летием Государственного академического театра драмы имени А.С.Пушкина.Вы по праву принадлежите к числу тех, кто в течение многих лет бережно хранит и приумножает традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение лучшие традиции и традиции своего народа, бережно хранит и передаёт из поколения в поколение'"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pu(\"Куцеву Диме\")[0]['generated_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "gNRcJwBw3WFP",
        "outputId": "d0ae3f28-3261-4cab-96a5-ecd198126b55"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Куцеву Диме, победителю  Паралимпийских летних игр в Токио в соревнованиях по плаванию в дисциплине  метров Уважаемый Дмитрий Анатольевич!Поздравляю Вас с триумфом.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине  метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине метров.Вы блестяще выступили на  Паралимпийских летних играх в Токио в соревнованиях по плаванию в дисциплине метров.Вы блестяще выступили на '"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pu(\"Мычалкин\")[0]['generated_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "2w_8w7Vh3ujp",
        "outputId": "ac6ddc3f-e747-48ee-da5a-39698bddf2a7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Мычалкин, заслуженный мастер спорта СССР, заслуженный мастер спорта СССР Уважаемый Владимир Иванович! Примите мои поздравления с -летием и самые добрые пожелания. Желаю Вам здоровья, благополучия и всего самого доброго. Владимир Путин       .   Текстовая версияКоллективу и ветеранам Государственного академического Большого театра России Дорогие друзья!Поздравляю вас с -летием Государственного академического Большого театра России.Вы по праву принадлежите к числу выдающихся театральных деятелей, которые внесли весомый вклад в развитие отечественного театра, внесли значимый вклад в развитие отечественной культуры.Важно, что сегодня Государственный академический Большой театр России является одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России, одним из крупнейших театров России'"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "jSo8B_fZ6MW2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for file in os.listdir('./gpt-letters'):\n",
        "  files.download(f'./gpt-letters/{file}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "xXyKxjB-9pOT",
        "outputId": "824e6edc-f53a-4b9b-f608-512adc5c3937"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f8cc651c-fe37-46c4-9dbb-62e06c7a04eb\", \"pytorch_model.bin\", 551317353)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_381da7bc-b1eb-47d6-ab2a-77dd409dcc89\", \"config.json\", 863)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a007d33e-ec3e-49bd-aa23-91e4dc99386c\", \"checkpoint-150\", 4096)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0528074c-08a9-4d16-ae22-2f88e724363a\", \"training_args.bin\", 2927)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cddcf226-1e1f-449c-bf16-fc4c87f72be1\", \"runs\", 4096)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for file in os.listdir('./gpt-letters'):\n",
        "  print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilYrtz_x9t2j",
        "outputId": "ab1d38d9-a9c5-4eee-cefc-e8ff08b82673"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch_model.bin\n",
            "config.json\n",
            "checkpoint-150\n",
            "training_args.bin\n",
            "runs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WIQkbeS8T8MH"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}